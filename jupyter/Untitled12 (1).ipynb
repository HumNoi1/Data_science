{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVHGCt7T54Dk",
        "outputId": "e9f4554f-8e46-4608-cdae-2074ae51a937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.11/dist-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "pip install tweepy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv4Y97f5599H",
        "outputId": "d7c81e7f-67aa-45ee-b456-afe906503d0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h_Jxqq06AFV",
        "outputId": "9d1f5cf7-1af7-4952-f8bd-d43629834515"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "dW-y3er16B1r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠\n",
        "time.sleep(15 * 60)  # ‡∏´‡∏¢‡∏∏‡∏î 15 ‡∏ô‡∏≤‡∏ó‡∏µ (‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)\n",
        "\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏ó‡∏ß‡∏µ‡∏ï‡∏à‡∏≤‡∏Å hashtag\n",
        "def collect_tweets_v2(bearer_token, hashtag, max_results=50): #‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâmax 100 for tw\n",
        "    import requests\n",
        "\n",
        "    url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
        "    headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
        "    params = {\n",
        "        \"query\": hashtag,\n",
        "        \"max_results\": max_results,\n",
        "        \"tweet.fields\": \"text,created_at\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers, params=params)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Request failed: {response.status_code}, {response.text}\")\n",
        "\n",
        "    data = response.json()\n",
        "    tweets = [{\"text\": tweet[\"text\"], \"created_at\": tweet[\"created_at\"]} for tweet in data.get(\"data\", [])]\n",
        "    return tweets\n",
        "\n",
        "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ\n",
        "\n",
        "# Twitter Bearer Token (replace with your token)\n",
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAANvXyAEAAAAAif28AxYfhBMs8gpubr%2BPN7YyS1E%3DnVX8XlgvfQDJO7mJ1oRbO0mFVVpJ6C1EAgdb7cpsheJsr0wfSp\"\n",
        "hashtag = \"#Health\"\n",
        "\n",
        "\n",
        "# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏ß‡∏µ‡∏ï\n",
        "tweets_data = collect_tweets_v2(BEARER_TOKEN, hashtag)\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏ß‡∏µ‡∏ï‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
        "df_tweets = pd.DataFrame(tweets_data)\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DataFrame\n",
        "print(df_tweets)\n",
        "\n",
        "# ‡πÄ‡∏ã‡∏ü‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel\n",
        "file_name = 'tweets_data2.xlsx'\n",
        "df_tweets.to_excel(file_name, index=False)\n",
        "\n",
        "print(f\"Data saved to {file_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qae6LUI56GKf",
        "outputId": "91f840bb-0f81-4277-feec-1bb4ee7cc9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 text  \\\n",
            "0   RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "1   RT @ClubGymBabes: Follow For More GymBabes! üçë ...   \n",
            "2   #diabetes #diabetesesp #diabetesawareness\\n#in...   \n",
            "3   RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "4   RT @BayBaysty: Are you interested in an except...   \n",
            "5   Imagine, @BigImpactHumans, having more #peace,...   \n",
            "6   Shaban Juma has been recognized as one of the ...   \n",
            "7   https://t.co/UWJCPLuStR\\nmy @enilevü™îmom\\n@Beta...   \n",
            "8   FDA bans Red No. 3 food dye in food, drinks: H...   \n",
            "9   https://t.co/JKa2qWKcqk\\nmy @enilevü™îmom\\n@Beta...   \n",
            "10  RT @NutritiousMind: How we feel in the moment ...   \n",
            "11  https://t.co/z0BfYHVhNC\\nmy @enilevü™îmom\\n@Beta...   \n",
            "12  https://t.co/UUHRGkokiU\\nmy @enilevü™îmom\\n@Beta...   \n",
            "13  RT @LavaletteAstrid: @NutritiousMind @smaksked...   \n",
            "14  RT @john_siracusa: Dr. Lori Shemek - Lose weig...   \n",
            "15  https://t.co/WwoWmhD2jc\\nmy @enilevü™îmom\\n@Beta...   \n",
            "16  https://t.co/yFSiIdRpcO\\nmy @enilevü™îmom\\n@Beta...   \n",
            "17  https://t.co/lASVGY1yqF\\nmy @enilevü™îmom\\n@Beta...   \n",
            "18  \"Body Mass Index (BMI) has been a health measu...   \n",
            "19  RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "20  https://t.co/OOSCvgGEUz\\nmy @enilevü™îmom\\n@Beta...   \n",
            "21  RT @youcanbhealthy: Add your health/beauty rel...   \n",
            "22  https://t.co/jHiGrQLK0E\\nmy @enilevü™îmom\\n@Beta...   \n",
            "23  RT @dlhampton: 8 Easy Habits That Will Rapidly...   \n",
            "24  RT @Eva_27Nutrition: Herbs that lower blood su...   \n",
            "25  RT @Eva_27Nutrition: Do you know that this foo...   \n",
            "26  RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "27  RT @Eva_27Nutrition: Did you know that this fo...   \n",
            "28  https://t.co/hqOVfEJRqR\\nmy @enilevü™îmom\\n@Beta...   \n",
            "29  https://t.co/VK6PwFkQiB\\nmy @enilevü™îmom\\n@Beta...   \n",
            "30  https://t.co/KTzLhITVMh\\nmy @enilevü™îmom\\n@Beta...   \n",
            "31  RT @TMCNaboJowar: ‡¶™‡ßÅ‡¶∞‡ßã ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶ü‡¶ø ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∂‡ßÅ‡¶®‡ßá ...   \n",
            "32  RT @DavidBroderDO: FDA bans red dye number 3 d...   \n",
            "33  https://t.co/P84kX0xdjg\\nmy @enilevü™îmom\\n@Beta...   \n",
            "34  RT @activist360_co: The plastics industry depl...   \n",
            "35  https://t.co/xt8axMbpPB\\nmy @enilevü™îmom\\n@Beta...   \n",
            "36  RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "37  RT @moayush: Digital Ayush, Healthier India!\\n...   \n",
            "38  https://t.co/kgLBozXPor\\nmy @enilevü™îmom\\n@Beta...   \n",
            "39  RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "40  https://t.co/OyvyVk4noU\\nmy @enilevü™îmom\\n@Beta...   \n",
            "41  RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "42  RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "43  RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "44  RT @TMCNaboJowar: ‡¶™‡ßÅ‡¶∞‡ßã ‡¶≠‡¶ø‡¶°‡¶ø‡¶ì‡¶ü‡¶ø ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∂‡ßÅ‡¶®‡ßá ...   \n",
            "45  RT @SavvyHuman: I‚Äôm READY!!!üòéüëå‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n#GoldenA...   \n",
            "46  7 Ways Your Body Is Telling You You‚Äôre Low on ...   \n",
            "47  RT @BapujiTelugu: ‡∞¨‡∞≤‡∞π‡±Ä‡∞®‡∞§‡∞®‡±Å ‡∞¶‡±Ç‡∞∞‡∞Ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø :\\n5 ‡∞ñ‡∞∞...   \n",
            "48  Kesar Ka Jaadoo Sehat Aur Saundary\\n#short #he...   \n",
            "49  RT @OrganicLiveFood: #Health Benefits of #Copp...   \n",
            "\n",
            "                  created_at  \n",
            "0   2025-01-16T03:01:53.000Z  \n",
            "1   2025-01-16T03:01:51.000Z  \n",
            "2   2025-01-16T03:01:32.000Z  \n",
            "3   2025-01-16T03:01:27.000Z  \n",
            "4   2025-01-16T03:00:19.000Z  \n",
            "5   2025-01-16T03:00:06.000Z  \n",
            "6   2025-01-16T03:00:02.000Z  \n",
            "7   2025-01-16T02:59:53.000Z  \n",
            "8   2025-01-16T02:59:40.000Z  \n",
            "9   2025-01-16T02:59:32.000Z  \n",
            "10  2025-01-16T02:59:26.000Z  \n",
            "11  2025-01-16T02:59:02.000Z  \n",
            "12  2025-01-16T02:58:53.000Z  \n",
            "13  2025-01-16T02:58:52.000Z  \n",
            "14  2025-01-16T02:58:48.000Z  \n",
            "15  2025-01-16T02:58:35.000Z  \n",
            "16  2025-01-16T02:58:28.000Z  \n",
            "17  2025-01-16T02:58:00.000Z  \n",
            "18  2025-01-16T02:57:42.000Z  \n",
            "19  2025-01-16T02:57:35.000Z  \n",
            "20  2025-01-16T02:57:14.000Z  \n",
            "21  2025-01-16T02:57:13.000Z  \n",
            "22  2025-01-16T02:56:51.000Z  \n",
            "23  2025-01-16T02:56:13.000Z  \n",
            "24  2025-01-16T02:56:09.000Z  \n",
            "25  2025-01-16T02:56:02.000Z  \n",
            "26  2025-01-16T02:55:59.000Z  \n",
            "27  2025-01-16T02:55:55.000Z  \n",
            "28  2025-01-16T02:55:24.000Z  \n",
            "29  2025-01-16T02:55:16.000Z  \n",
            "30  2025-01-16T02:55:05.000Z  \n",
            "31  2025-01-16T02:55:02.000Z  \n",
            "32  2025-01-16T02:54:34.000Z  \n",
            "33  2025-01-16T02:54:17.000Z  \n",
            "34  2025-01-16T02:54:09.000Z  \n",
            "35  2025-01-16T02:54:09.000Z  \n",
            "36  2025-01-16T02:53:44.000Z  \n",
            "37  2025-01-16T02:53:28.000Z  \n",
            "38  2025-01-16T02:53:26.000Z  \n",
            "39  2025-01-16T02:53:22.000Z  \n",
            "40  2025-01-16T02:53:20.000Z  \n",
            "41  2025-01-16T02:52:50.000Z  \n",
            "42  2025-01-16T02:52:22.000Z  \n",
            "43  2025-01-16T02:51:07.000Z  \n",
            "44  2025-01-16T02:51:07.000Z  \n",
            "45  2025-01-16T02:51:04.000Z  \n",
            "46  2025-01-16T02:51:00.000Z  \n",
            "47  2025-01-16T02:50:47.000Z  \n",
            "48  2025-01-16T02:50:15.000Z  \n",
            "49  2025-01-16T02:49:35.000Z  \n",
            "Data saved to tweets_data2.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pythainlp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tabku46Pl3a",
        "outputId": "6838a6eb-fcef-4726-ef54-bb888adbbcd4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.11/dist-packages (5.0.5)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pre data"
      ],
      "metadata": {
        "id": "0DISgrhcRzpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Step 1.1: Preprocess Tweets\n",
        "def preprocess_tweet(tweet, language='en'):\n",
        "    if tweet is None:\n",
        "        return \"\"  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤ tweet ‡πÄ‡∏õ‡πá‡∏ô None\n",
        "\n",
        "    tweet = str(tweet)  # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á\n",
        "\n",
        "    if language == 'th':\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        tweet = word_tokenize(tweet)  # ‡πÉ‡∏ä‡πâ pythainlp ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "\n",
        "        # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        tweet = re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', ' '.join(tweet))  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏Å‡πà‡∏≠‡∏ô\n",
        "        tweet = tweet.lower()\n",
        "\n",
        "        # ‡πÇ‡∏´‡∏•‡∏î stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å `stopwords` ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á)\n",
        "        stop_words_th = set([\n",
        "            '‡πÅ‡∏ï‡πà', '‡πÅ‡∏•‡∏∞', '‡∏ó‡∏µ‡πà', '‡∏à‡∏≤‡∏Å', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏à‡∏∞', '‡∏Å‡∏±‡∏ö', '‡πÉ‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô', '‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô', '‡∏ã‡∏∂‡πà‡∏á', '‡∏ô‡∏±‡πâ‡∏ô', '‡∏´‡∏£‡∏∑‡∏≠'\n",
        "        ])  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≥ stopwords ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á\n",
        "\n",
        "        # ‡∏•‡∏ö‡∏Ñ‡∏≥ stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        words = tweet.split()\n",
        "        words = [word for word in words if word not in stop_words_th]\n",
        "\n",
        "    else:\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©\n",
        "        nltk.download('stopwords')\n",
        "        stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "        # ‡∏•‡∏ö mentions, hashtags, URLs, ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        tweet = re.sub(r'@\\w+|#\\w+|http\\S+|[^A-Za-z0-9 ]+', '', tweet)\n",
        "        tweet = tweet.lower()\n",
        "\n",
        "        # ‡∏•‡∏ö stopwords\n",
        "        words = tweet.split()\n",
        "        words = [word for word in words if word not in stop_words_en]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "# Step 2: Read Dataset and Apply Preprocessing\n",
        "def main(file_path):\n",
        "    # Read the dataset\n",
        "    df = pd.read_excel(file_path, sheet_name='data')  # ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å sheet ‡∏ä‡∏∑‡πà‡∏≠ 'data'\n",
        "\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'tweetText' ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "    df['tweetText'] = df['tweetText'].fillna('')\n",
        "\n",
        "    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "    df['processed_tweet'] = df['tweetText'].apply(preprocess_tweet, language='th')\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 2 ‡πÅ‡∏ñ‡∏ß‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™\n",
        "    print(\"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£ preprocess:\")\n",
        "    for label in df['hashtage'].unique():\n",
        "        print(f\"\\n‡∏Ñ‡∏•‡∏≤‡∏™: {label}\")\n",
        "        sample = df[df['hashtage'] == label].head(2)  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 2 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™\n",
        "        print(sample[['tweetText', 'processed_tweet']])\n",
        "\n",
        "\n",
        "# Run the main function with the path to your dataset\n",
        "main('thai_text_from_hashtage.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiYsaINcJtRC",
        "outputId": "912aee81-03b4-4deb-b9af-b2128a3a17fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£ preprocess:\n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡∏™‡πâ‡∏°‡∏î‡∏¥‡∏ß‡∏∞\n",
            "                                           tweetText  \\\n",
            "0  @onlynexnx_ ‡∏ä‡∏µ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü ‡πÄ‡∏´‡∏¢‡∏¥‡∏ô ‡∏Æ‡πá‡∏≠‡∏ö ‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡∏ó‡∏±‡∏ô‡∏ï‡∏Å‡∏£‡∏£‡∏°...   \n",
            "1  @Noeywith789 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡∏™‡πâ‡∏°‡∏°‡∏≤‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡∏ñ‡∏∂‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏¢‡∏Ñ‡∏±‡∏ö\\n#‡πÄ...   \n",
            "\n",
            "                                     processed_tweet  \n",
            "0  onlynexnx ‡∏ä‡∏µ ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü ‡πÄ‡∏´ ‡∏¢‡∏¥‡∏ô ‡∏Æ‡πá‡∏≠‡∏ö ‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å ‡∏ó‡∏±‡∏ô‡∏ï‡∏Å‡∏£‡∏£...  \n",
            "1  noeywith789 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á ‡∏™‡πâ‡∏° ‡∏°‡∏≤ ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü ‡∏ñ‡∏∂‡∏á‡∏ó‡∏µ‡πà ‡πÄ‡∏•‡∏¢ ‡∏Ñ‡∏±...  \n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: ‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡πà‡∏≠‡∏ô‡πÄ‡∏¢‡∏≤‡∏ß‡πå\n",
            "                                             tweetText  \\\n",
            "100  ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏ß\\n‡πÅ‡∏≠‡∏î‡πÑ‡∏•‡∏ô‡πå‡∏°‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞‡∏û‡∏µ‡πà\\n@tt356‡∏°‡∏µ‡πÅ‡∏≠‡∏î...   \n",
            "101  ùôºùöòùöòùöñùöíùöó\\n\\n#‡∏õ‡∏±‡πä‡∏°‡πÑ‡∏•‡∏Ñ‡πå /#‡∏õ‡∏±‡πä‡∏°‡∏ß‡∏¥‡∏ß\\n\\n‚û• ‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥...   \n",
            "\n",
            "                                       processed_tweet  \n",
            "100  ‡∏≠‡∏¢‡∏≤‡∏Å ‡πÄ‡∏™‡∏µ‡∏¢‡∏ß ‡πÅ‡∏≠‡∏î ‡πÑ‡∏•‡∏ô‡πå ‡∏°‡∏≤ ‡πÄ‡∏•‡∏¢ ‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏û‡∏µ‡πà tt356 ‡∏°‡∏µ ‡πÅ...  \n",
            "101  ‡∏õ‡∏±‡πä‡∏° ‡πÑ‡∏•‡∏Ñ‡πå ‡∏õ‡∏±‡πä‡∏° ‡∏ß‡∏¥‡∏ß ‡∏á‡∏≤‡∏ô ‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥ ‡∏°‡∏µ ‡∏ï‡∏±‡∏ß‡∏ï‡∏ô ‡∏á‡∏≤‡∏ô ‡πÑ...  \n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: ‡∏î‡πâ‡∏≠‡∏°‡∏†‡∏†\n",
            "                                             tweetText  \\\n",
            "128  wHATTTTT OMSGSGSGGSGSGSG\\n\\n#LOfficielThailand...   \n",
            "129  ‡∏´‡∏ô‡∏∏‡πà‡∏°‡πÅ‡∏ö‡∏î‡∏ö‡∏≠‡∏¢ ‡∏Å‡∏±‡∏ö‡∏´‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏±‡∏Å‡∏Ü‡πà‡∏≤ ‡∏Ñ‡∏≤‡πÅ‡∏£‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏°‡∏±‡∏ô‡πÑ‡∏î‡πâ ‡∏≠‡∏¥...   \n",
            "\n",
            "                                       processed_tweet  \n",
            "128  whattttt omsgsgsggsgsgsg lofficielthailand lof...  \n",
            "129  ‡∏´‡∏ô‡∏∏‡πà‡∏° ‡πÅ‡∏ö‡∏î ‡∏ö‡∏≠‡∏¢ ‡∏´‡∏ô‡∏∏‡πà‡∏° ‡∏ô‡∏±‡∏Å‡∏Ü‡πà‡∏≤ ‡∏Ñ‡∏≤‡πÅ‡∏£‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡∏°‡∏±‡∏ô ‡∏≠‡∏¥‡∏ô ...  \n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: meenbabe\n",
            "                                             tweetText  \\\n",
            "228  MB didn't say, \"I wanna spend time with u.\" \\n...   \n",
            "229  ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏≤‡∏Å .... ‡∏û‡∏π‡∏î‡πÑ‡∏´‡∏° ‡πÅ‡∏ï‡πà‡πÄ‡∏Ç‡∏≤‡∏û‡∏π‡∏î‡∏Å‡∏±‡∏ô‡πÑ‡∏õ‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏ô...   \n",
            "\n",
            "                                       processed_tweet  \n",
            "228  mb didn t say i wanna spend time with u mb are...  \n",
            "229  ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ‡∏°‡∏≤‡∏Å ‡∏û‡∏π‡∏î ‡πÑ‡∏´‡∏° ‡πÄ‡∏Ç‡∏≤ ‡∏û‡∏π‡∏î ‡∏Å‡∏±‡∏ô ‡πÑ‡∏õ ‡∏´‡∏°‡∏î ‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏ô‡πâ...  \n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: ‡πÅ‡∏ï‡∏á‡πÇ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∏‡∏ï‡∏¥\n",
            "                                             tweetText  \\\n",
            "328  ‡∏£‡∏µ‡∏£‡∏±‡∏ô ‚Ä¶‚Ä¶‚Ä¶.‡∏ß‡∏±‡∏ô‡πÅ‡∏ñ‡∏•‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏î‡∏µ 26  ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2565\\...   \n",
            "329  ‡∏£‡∏µ‡∏£‡∏±‡∏ô ‚Ä¶‚Ä¶‚Ä¶.‡∏ß‡∏±‡∏ô‡πÅ‡∏ñ‡∏•‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏î‡∏µ 26  ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2565\\...   \n",
            "\n",
            "                                       processed_tweet  \n",
            "328  ‡∏£‡∏µ‡∏£‡∏±‡∏ô ‡∏ß‡∏±‡∏ô ‡πÅ‡∏ñ‡∏•‡∏á ‡∏™‡∏£‡∏∏‡∏õ ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô ‡∏Ñ‡∏î‡∏µ 26 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2565 ‡πÅ...  \n",
            "329  ‡∏£‡∏µ‡∏£‡∏±‡∏ô ‡∏ß‡∏±‡∏ô ‡πÅ‡∏ñ‡∏•‡∏á ‡∏™‡∏£‡∏∏‡∏õ ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô ‡∏Ñ‡∏î‡∏µ 26 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2565 ‡πÅ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF"
      ],
      "metadata": {
        "id": "vWc7KCvDSDoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 1: Preprocess Tweets\n",
        "def preprocess_tweet(tweet):\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # ‡∏•‡∏ö mentions, hashtags, URLs, ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "    tweet = re.sub(r'@\\w+|#\\w+|http\\S+|[^A-Za-z0-9 ]+', '', tweet)\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    # ‡∏•‡∏ö stopwords\n",
        "    words = tweet.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Step 2: Feature Extraction using TF-IDF\n",
        "def extract_features(corpus, model_type='tfidf'):\n",
        "    if model_type == 'tfidf':\n",
        "        # ‡πÉ‡∏ä‡πâ TfidfVectorizer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "        return features, vectorizer\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method: choose 'tfidf'\")\n",
        "\n",
        "# Step 3: Train and Evaluate Models\n",
        "def train_and_evaluate_models(features, labels):\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(),\n",
        "        'SVM': SVC(),\n",
        "        'Random Forest': RandomForestClassifier(),\n",
        "        'KNN': KNeighborsClassifier()\n",
        "    }\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    results = []\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        accuracy = model.score(X_test, y_test)\n",
        "        y_pred = model.predict(X_test)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Accuracy': round(accuracy, 4),\n",
        "            'Precision': round(report['accuracy'], 4),\n",
        "            'Recall': round(report['accuracy'], 4),\n",
        "            'F1-Score': round(report['accuracy'], 4),\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Step 4: Load Dataset from Excel\n",
        "def load_data(file_path):\n",
        "    df = pd.read_excel(file_path, sheet_name='data')\n",
        "    tweets = df['tweetText'].apply(preprocess_tweet)\n",
        "    labels = df['hashtage']\n",
        "    return tweets, labels\n",
        "\n",
        "# Step 5: Main Function to Execute\n",
        "def main(file_path):\n",
        "    tweets, labels = load_data(file_path)\n",
        "\n",
        "    # Extract features using TF-IDF\n",
        "    features, vectorizer = extract_features(tweets, model_type='tfidf')\n",
        "\n",
        "    # Train and Evaluate Models\n",
        "    results_df = train_and_evaluate_models(features, labels)\n",
        "\n",
        "    # Show results\n",
        "    print(results_df)\n",
        "\n",
        "# Run the main function with the path to your dataset\n",
        "main('thai_text_from_hashtage.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpAreVicSFni",
        "outputId": "82fc6cda-888c-44a1-c02e-9a1de05b1e4e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model  Accuracy  Precision  Recall  F1-Score\n",
            "0  Logistic Regression    0.3837     0.3837  0.3837    0.3837\n",
            "1                  SVM    0.6512     0.6512  0.6512    0.6512\n",
            "2        Random Forest    0.6395     0.6395  0.6395    0.6395\n",
            "3                  KNN    0.5000     0.5000  0.5000    0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "word to vac"
      ],
      "metadata": {
        "id": "L9XUEulxS7mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Step 1: Preprocess Tweets\n",
        "def preprocess_tweet(tweet):\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # ‡∏•‡∏ö mentions, hashtags, URLs, ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "    tweet = re.sub(r'@\\w+|#\\w+|http\\S+|[^A-Za-z0-9 ]+', '', tweet)\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    # ‡∏•‡∏ö stopwords\n",
        "    words = tweet.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Step 2: Feature Extraction using Word2Vec and StandardScaler\n",
        "def extract_features(corpus, model_type='word2vec'):\n",
        "    if model_type == 'word2vec':\n",
        "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á model Word2Vec\n",
        "        model = Word2Vec(corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
        "        features = []\n",
        "        for sentence in corpus:\n",
        "            sentence_vector = np.zeros(100)  # ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
        "            count = 0\n",
        "            for word in sentence:\n",
        "                if word in model.wv:\n",
        "                    sentence_vector += model.wv[word]\n",
        "                    count += 1\n",
        "            if count > 0:\n",
        "                sentence_vector /= count\n",
        "            features.append(sentence_vector)\n",
        "\n",
        "        # ‡πÉ‡∏ä‡πâ StandardScaler ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "        scaler = StandardScaler()\n",
        "        features = scaler.fit_transform(np.array(features))\n",
        "\n",
        "        return features\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method: choose 'word2vec'\")\n",
        "\n",
        "# Step 3: Train and Evaluate Models\n",
        "def train_and_evaluate_models(features, labels):\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(),\n",
        "        'SVM': SVC(),\n",
        "        'Random Forest': RandomForestClassifier(),\n",
        "        'KNN': KNeighborsClassifier()\n",
        "    }\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    results = []\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        accuracy = model.score(X_test, y_test)\n",
        "        y_pred = model.predict(X_test)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Accuracy': round(accuracy, 4),\n",
        "            'Precision': round(report['accuracy'], 4),\n",
        "            'Recall': round(report['accuracy'], 4),\n",
        "            'F1-Score': round(report['accuracy'], 4),\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Step 4: Load Dataset from Excel\n",
        "def load_data(file_path):\n",
        "    df = pd.read_excel(file_path, sheet_name='data')\n",
        "    tweets = df['tweetText'].apply(preprocess_tweet)\n",
        "    labels = df['hashtage']\n",
        "    return tweets, labels\n",
        "\n",
        "# Step 5: Main Function to Execute\n",
        "def main(file_path):\n",
        "    tweets, labels = load_data(file_path)\n",
        "\n",
        "    # Tokenize the text into words\n",
        "    corpus = [tweet.split() for tweet in tweets]\n",
        "\n",
        "    # Extract features\n",
        "    features = extract_features(corpus, model_type='word2vec')\n",
        "\n",
        "    # Train and Evaluate Models\n",
        "    results_df = train_and_evaluate_models(features, labels)\n",
        "\n",
        "    # Show results\n",
        "    print(results_df)\n",
        "\n",
        "# Run the main function with the path to your dataset\n",
        "main('thai_text_from_hashtage.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvY-tg4ES7KH",
        "outputId": "1cc22fc4-5d4a-4990-8837-a321bfe71e31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model  Accuracy  Precision  Recall  F1-Score\n",
            "0  Logistic Regression    0.6163     0.6163  0.6163    0.6163\n",
            "1                  SVM    0.6279     0.6279  0.6279    0.6279\n",
            "2        Random Forest    0.6512     0.6512  0.6512    0.6512\n",
            "3                  KNN    0.4884     0.4884  0.4884    0.4884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bow"
      ],
      "metadata": {
        "id": "W1XZIP5TTUWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 1: Preprocess Tweets\n",
        "def preprocess_tweet(tweet):\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # ‡∏•‡∏ö mentions, hashtags, URLs, ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "    tweet = re.sub(r'@\\w+|#\\w+|http\\S+|[^A-Za-z0-9 ]+', '', tweet)\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    # ‡∏•‡∏ö stopwords\n",
        "    words = tweet.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Step 2: Feature Extraction using Bag of Words (BoW)\n",
        "def extract_features(corpus, model_type='bow'):\n",
        "    if model_type == 'bow':\n",
        "        # ‡πÉ‡∏ä‡πâ CountVectorizer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå\n",
        "        vectorizer = CountVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "        return features, vectorizer\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method: choose 'bow'\")\n",
        "\n",
        "# Step 3: Train and Evaluate Models\n",
        "def train_and_evaluate_models(features, labels):\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(),\n",
        "        'SVM': SVC(),\n",
        "        'Random Forest': RandomForestClassifier(),\n",
        "        'KNN': KNeighborsClassifier()\n",
        "    }\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    results = []\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        accuracy = model.score(X_test, y_test)\n",
        "        y_pred = model.predict(X_test)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Accuracy': round(accuracy, 4),\n",
        "            'Precision': round(report['accuracy'], 4),\n",
        "            'Recall': round(report['accuracy'], 4),\n",
        "            'F1-Score': round(report['accuracy'], 4),\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Step 4: Load Dataset from Excel\n",
        "def load_data(file_path):\n",
        "    df = pd.read_excel(file_path, sheet_name='data')\n",
        "    tweets = df['tweetText'].apply(preprocess_tweet)\n",
        "    labels = df['hashtage']\n",
        "    return tweets, labels\n",
        "\n",
        "# Step 5: Main Function to Execute\n",
        "def main(file_path):\n",
        "    tweets, labels = load_data(file_path)\n",
        "\n",
        "    # Extract features using Bag of Words (BoW)\n",
        "    features, vectorizer = extract_features(tweets, model_type='bow')\n",
        "\n",
        "    # Train and Evaluate Models\n",
        "    results_df = train_and_evaluate_models(features, labels)\n",
        "\n",
        "    # Show results\n",
        "    print(results_df)\n",
        "\n",
        "# Run the main function with the path to your dataset\n",
        "main('thai_text_from_hashtage.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZapN6RhTU8U",
        "outputId": "6e1e6bdb-4b10-4038-b859-8d00dcd3020c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model  Accuracy  Precision  Recall  F1-Score\n",
            "0  Logistic Regression    0.6163     0.6163  0.6163    0.6163\n",
            "1                  SVM    0.6163     0.6163  0.6163    0.6163\n",
            "2        Random Forest    0.6628     0.6628  0.6628    0.6628\n",
            "3                  KNN    0.4070     0.4070  0.4070    0.4070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test 3 method"
      ],
      "metadata": {
        "id": "WkoXVluATw1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Step 1: Preprocess Tweets\n",
        "def preprocess_tweet(tweet):\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Remove mentions, hashtags, URLs, and special characters\n",
        "    tweet = re.sub(r'@\\w+|#\\w+|http\\S+|[^A-Za-z0-9 ]+', '', tweet)\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    words = tweet.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Step 2: Feature Extraction using Bag of Words, TF-IDF, Word2Vec\n",
        "def extract_features(corpus, method='bow'):\n",
        "    if method == 'bow':\n",
        "        vectorizer = CountVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    elif method == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    elif method == 'word2vec':\n",
        "        model = Word2Vec(sentences=[tweet.split() for tweet in corpus], vector_size=100, window=5, min_count=1, workers=4)\n",
        "        features = np.array([np.mean([model.wv[word] for word in tweet.split() if word in model.wv] or [np.zeros(100)], axis=0) for tweet in corpus])\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method: choose 'bow', 'tfidf', or 'word2vec'\")\n",
        "    return features\n",
        "\n",
        "# Step 3: Train and Evaluate Models with Cross-Validation\n",
        "def train_and_evaluate_models(features, labels, folds=[5, 10]):\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(),\n",
        "        'SVM': SVC(),\n",
        "        'Random Forest': RandomForestClassifier(),\n",
        "        'KNN': KNeighborsClassifier()\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    for model_name, model in models.items():\n",
        "        for fold in folds:\n",
        "            cv = KFold(n_splits=fold, shuffle=True, random_state=42)\n",
        "            accuracy = cross_val_score(model, features, labels, cv=cv, scoring='accuracy')\n",
        "            results.append({\n",
        "                'Model': model_name,\n",
        "                'Method': 'BoW',  # Add 'BoW', 'TF-IDF', or 'Word2Vec' based on your extraction method\n",
        "                'Fold': fold,\n",
        "                'Mean Accuracy': round(np.mean(accuracy), 4),\n",
        "                'Standard Deviation': round(np.std(accuracy), 4)\n",
        "            })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Step 4: Load Dataset from Excel\n",
        "def load_data(file_path):\n",
        "    df = pd.read_excel(file_path, sheet_name='data')\n",
        "    tweets = df['tweetText'].apply(preprocess_tweet)\n",
        "    labels = df['hashtage']\n",
        "    return tweets, labels\n",
        "\n",
        "# Step 5: Main Function to Execute\n",
        "def main(file_path):\n",
        "    tweets, labels = load_data(file_path)\n",
        "\n",
        "    # Extract features using different methods\n",
        "    methods = ['bow', 'tfidf', 'word2vec']\n",
        "\n",
        "    all_results = []\n",
        "    for method in methods:\n",
        "        features = extract_features(tweets, method)\n",
        "\n",
        "        # Train and Evaluate Models\n",
        "        results_df = train_and_evaluate_models(features, labels)\n",
        "        results_df['Method'] = method\n",
        "        all_results.append(results_df)\n",
        "\n",
        "    # Combine results from all feature extraction methods\n",
        "    final_results = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "    # Show results\n",
        "    print(final_results)\n",
        "\n",
        "# Run the main function with the path to your dataset\n",
        "main('thai_text_from_hashtage.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v1PQGIkTyAi",
        "outputId": "320482b6-89f2-4457-916a-0a99ce2461a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Model    Method  Fold  Mean Accuracy  Standard Deviation\n",
            "0   Logistic Regression       bow     5         0.5514              0.0409\n",
            "1   Logistic Regression       bow    10         0.5283              0.0935\n",
            "2                   SVM       bow     5         0.5538              0.0499\n",
            "3                   SVM       bow    10         0.5516              0.0767\n",
            "4         Random Forest       bow     5         0.5537              0.0514\n",
            "5         Random Forest       bow    10         0.5608              0.1009\n",
            "6                   KNN       bow     5         0.3972              0.0234\n",
            "7                   KNN       bow    10         0.3972              0.0613\n",
            "8   Logistic Regression     tfidf     5         0.4698              0.0521\n",
            "9   Logistic Regression     tfidf    10         0.4933              0.0996\n",
            "10                  SVM     tfidf     5         0.5609              0.0716\n",
            "11                  SVM     tfidf    10         0.5772              0.0922\n",
            "12        Random Forest     tfidf     5         0.5561              0.0516\n",
            "13        Random Forest     tfidf    10         0.5631              0.0915\n",
            "14                  KNN     tfidf     5         0.3761              0.0488\n",
            "15                  KNN     tfidf    10         0.3669              0.0720\n",
            "16  Logistic Regression  word2vec     5         0.2129              0.0852\n",
            "17  Logistic Regression  word2vec    10         0.1898              0.1053\n",
            "18                  SVM  word2vec     5         0.5515              0.0536\n",
            "19                  SVM  word2vec    10         0.5609              0.0785\n",
            "20        Random Forest  word2vec     5         0.5493              0.0672\n",
            "21        Random Forest  word2vec    10         0.5703              0.0877\n",
            "22                  KNN  word2vec     5         0.3996              0.0645\n",
            "23                  KNN  word2vec    10         0.4089              0.1089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble model"
      ],
      "metadata": {
        "id": "oBtkvuAcVyfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Step 1.1: Preprocess Tweets\n",
        "def preprocess_tweet(tweet, language='en'):\n",
        "    if tweet is None:\n",
        "        return \"\"  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤ tweet ‡πÄ‡∏õ‡πá‡∏ô None\n",
        "\n",
        "    tweet = str(tweet)  # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á\n",
        "\n",
        "    if language == 'th':\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        tweet = word_tokenize(tweet)  # ‡πÉ‡∏ä‡πâ pythainlp ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "\n",
        "        # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        tweet = re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', ' '.join(tweet))  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏Å‡πà‡∏≠‡∏ô\n",
        "        tweet = tweet.lower()\n",
        "\n",
        "        # ‡πÇ‡∏´‡∏•‡∏î stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å `stopwords` ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á)\n",
        "        stop_words_th = set([\n",
        "            '‡πÅ‡∏ï‡πà', '‡πÅ‡∏•‡∏∞', '‡∏ó‡∏µ‡πà', '‡∏à‡∏≤‡∏Å', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏à‡∏∞', '‡∏Å‡∏±‡∏ö', '‡πÉ‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô', '‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô', '‡∏ã‡∏∂‡πà‡∏á', '‡∏ô‡∏±‡πâ‡∏ô', '‡∏´‡∏£‡∏∑‡∏≠'\n",
        "        ])  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≥ stopwords ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á\n",
        "\n",
        "        # ‡∏•‡∏ö‡∏Ñ‡∏≥ stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        words = tweet.split()\n",
        "        words = [word for word in words if word not in stop_words_th]\n",
        "\n",
        "    else:\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©\n",
        "        nltk.download('stopwords')\n",
        "        stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "        # ‡∏•‡∏ö mentions, hashtags, URLs, ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        tweet = re.sub(r'@\\w+|#\\w+|http\\S+|[^A-Za-z0-9 ]+', '', tweet)\n",
        "        tweet = tweet.lower()\n",
        "\n",
        "        # ‡∏•‡∏ö stopwords\n",
        "        words = tweet.split()\n",
        "        words = [word for word in words if word not in stop_words_en]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "# Step 2: Read Dataset and Apply Preprocessing\n",
        "def main(file_path):\n",
        "    # Read the dataset\n",
        "    df = pd.read_excel(file_path, sheet_name='data')  # ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å sheet ‡∏ä‡∏∑‡πà‡∏≠ 'data'\n",
        "\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'tweetText' ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "    df['tweetText'] = df['tweetText'].fillna('')\n",
        "\n",
        "    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "    df['processed_tweet'] = df['tweetText'].apply(preprocess_tweet, language='th')\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 2 ‡πÅ‡∏ñ‡∏ß‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™\n",
        "    print(\"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£ preprocess:\")\n",
        "    for label in df['hashtage'].unique():\n",
        "        print(f\"\\n‡∏Ñ‡∏•‡∏≤‡∏™: {label}\")\n",
        "        sample = df[df['hashtage'] == label].head(2)  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 2 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™\n",
        "        print(sample[['tweetText', 'processed_tweet']])\n",
        "\n",
        "\n",
        "# Run the main function with the path to your dataset\n",
        "main('thai_text_from_hashtage.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuJthylFV6RU",
        "outputId": "63786ab4-e4e5-4b9c-d72e-a556ec272f91"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£ preprocess:\n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡∏™‡πâ‡∏°‡∏î‡∏¥‡∏ß‡∏∞\n",
            "                                           tweetText  \\\n",
            "0  @onlynexnx_ ‡∏ä‡∏µ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü ‡πÄ‡∏´‡∏¢‡∏¥‡∏ô ‡∏Æ‡πá‡∏≠‡∏ö ‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å‡∏ó‡∏±‡∏ô‡∏ï‡∏Å‡∏£‡∏£‡∏°...   \n",
            "1  @Noeywith789 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡∏™‡πâ‡∏°‡∏°‡∏≤‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü‡∏ñ‡∏∂‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏¢‡∏Ñ‡∏±‡∏ö\\n#‡πÄ...   \n",
            "\n",
            "                                     processed_tweet  \n",
            "0  onlynexnx ‡∏ä‡∏µ ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü ‡πÄ‡∏´ ‡∏¢‡∏¥‡∏ô ‡∏Æ‡πá‡∏≠‡∏ö ‡∏Ñ‡∏•‡∏¥‡∏ô‡∏¥‡∏Å ‡∏ó‡∏±‡∏ô‡∏ï‡∏Å‡∏£‡∏£...  \n",
            "1  noeywith789 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á ‡∏™‡πâ‡∏° ‡∏°‡∏≤ ‡πÄ‡∏™‡∏¥‡∏£‡πå‡∏ü ‡∏ñ‡∏∂‡∏á‡∏ó‡∏µ‡πà ‡πÄ‡∏•‡∏¢ ‡∏Ñ‡∏±...  \n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: ‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡πà‡∏≠‡∏ô‡πÄ‡∏¢‡∏≤‡∏ß‡πå\n",
            "                                             tweetText  \\\n",
            "100  ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏ß\\n‡πÅ‡∏≠‡∏î‡πÑ‡∏•‡∏ô‡πå‡∏°‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞‡∏û‡∏µ‡πà\\n@tt356‡∏°‡∏µ‡πÅ‡∏≠‡∏î...   \n",
            "101  ùôºùöòùöòùöñùöíùöó\\n\\n#‡∏õ‡∏±‡πä‡∏°‡πÑ‡∏•‡∏Ñ‡πå /#‡∏õ‡∏±‡πä‡∏°‡∏ß‡∏¥‡∏ß\\n\\n‚û• ‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥...   \n",
            "\n",
            "                                       processed_tweet  \n",
            "100  ‡∏≠‡∏¢‡∏≤‡∏Å ‡πÄ‡∏™‡∏µ‡∏¢‡∏ß ‡πÅ‡∏≠‡∏î ‡πÑ‡∏•‡∏ô‡πå ‡∏°‡∏≤ ‡πÄ‡∏•‡∏¢ ‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏û‡∏µ‡πà tt356 ‡∏°‡∏µ ‡πÅ...  \n",
            "101  ‡∏õ‡∏±‡πä‡∏° ‡πÑ‡∏•‡∏Ñ‡πå ‡∏õ‡∏±‡πä‡∏° ‡∏ß‡∏¥‡∏ß ‡∏á‡∏≤‡∏ô ‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥ ‡∏°‡∏µ ‡∏ï‡∏±‡∏ß‡∏ï‡∏ô ‡∏á‡∏≤‡∏ô ‡πÑ...  \n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: ‡∏î‡πâ‡∏≠‡∏°‡∏†‡∏†\n",
            "                                             tweetText  \\\n",
            "128  wHATTTTT OMSGSGSGGSGSGSG\\n\\n#LOfficielThailand...   \n",
            "129  ‡∏´‡∏ô‡∏∏‡πà‡∏°‡πÅ‡∏ö‡∏î‡∏ö‡∏≠‡∏¢ ‡∏Å‡∏±‡∏ö‡∏´‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏±‡∏Å‡∏Ü‡πà‡∏≤ ‡∏Ñ‡∏≤‡πÅ‡∏£‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏°‡∏±‡∏ô‡πÑ‡∏î‡πâ ‡∏≠‡∏¥...   \n",
            "\n",
            "                                       processed_tweet  \n",
            "128  whattttt omsgsgsggsgsgsg lofficielthailand lof...  \n",
            "129  ‡∏´‡∏ô‡∏∏‡πà‡∏° ‡πÅ‡∏ö‡∏î ‡∏ö‡∏≠‡∏¢ ‡∏´‡∏ô‡∏∏‡πà‡∏° ‡∏ô‡∏±‡∏Å‡∏Ü‡πà‡∏≤ ‡∏Ñ‡∏≤‡πÅ‡∏£‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡∏°‡∏±‡∏ô ‡∏≠‡∏¥‡∏ô ...  \n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: meenbabe\n",
            "                                             tweetText  \\\n",
            "228  MB didn't say, \"I wanna spend time with u.\" \\n...   \n",
            "229  ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏°‡∏≤‡∏Å .... ‡∏û‡∏π‡∏î‡πÑ‡∏´‡∏° ‡πÅ‡∏ï‡πà‡πÄ‡∏Ç‡∏≤‡∏û‡∏π‡∏î‡∏Å‡∏±‡∏ô‡πÑ‡∏õ‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏ô...   \n",
            "\n",
            "                                       processed_tweet  \n",
            "228  mb didn t say i wanna spend time with u mb are...  \n",
            "229  ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ‡∏°‡∏≤‡∏Å ‡∏û‡∏π‡∏î ‡πÑ‡∏´‡∏° ‡πÄ‡∏Ç‡∏≤ ‡∏û‡∏π‡∏î ‡∏Å‡∏±‡∏ô ‡πÑ‡∏õ ‡∏´‡∏°‡∏î ‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏ô‡πâ...  \n",
            "\n",
            "‡∏Ñ‡∏•‡∏≤‡∏™: ‡πÅ‡∏ï‡∏á‡πÇ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∏‡∏ï‡∏¥\n",
            "                                             tweetText  \\\n",
            "328  ‡∏£‡∏µ‡∏£‡∏±‡∏ô ‚Ä¶‚Ä¶‚Ä¶.‡∏ß‡∏±‡∏ô‡πÅ‡∏ñ‡∏•‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏î‡∏µ 26  ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2565\\...   \n",
            "329  ‡∏£‡∏µ‡∏£‡∏±‡∏ô ‚Ä¶‚Ä¶‚Ä¶.‡∏ß‡∏±‡∏ô‡πÅ‡∏ñ‡∏•‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏î‡∏µ 26  ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2565\\...   \n",
            "\n",
            "                                       processed_tweet  \n",
            "328  ‡∏£‡∏µ‡∏£‡∏±‡∏ô ‡∏ß‡∏±‡∏ô ‡πÅ‡∏ñ‡∏•‡∏á ‡∏™‡∏£‡∏∏‡∏õ ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô ‡∏Ñ‡∏î‡∏µ 26 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2565 ‡πÅ...  \n",
            "329  ‡∏£‡∏µ‡∏£‡∏±‡∏ô ‡∏ß‡∏±‡∏ô ‡πÅ‡∏ñ‡∏•‡∏á ‡∏™‡∏£‡∏∏‡∏õ ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô ‡∏Ñ‡∏î‡∏µ 26 ‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô 2565 ‡πÅ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble_Extraction"
      ],
      "metadata": {
        "id": "Cz66ouoIXlkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "# Step 1.1: Preprocess Tweets\n",
        "def preprocess_tweet(tweet, language='en'):\n",
        "    if tweet is None:\n",
        "        return \"\"  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤ tweet ‡πÄ‡∏õ‡πá‡∏ô None\n",
        "\n",
        "    tweet = str(tweet)  # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á\n",
        "\n",
        "    if language == 'th':\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        tweet = word_tokenize(tweet)  # ‡πÉ‡∏ä‡πâ pythainlp ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "\n",
        "        # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        tweet = re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', ' '.join(tweet))  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏Å‡πà‡∏≠‡∏ô\n",
        "        tweet = tweet.lower()\n",
        "\n",
        "        # ‡πÇ‡∏´‡∏•‡∏î stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å `stopwords` ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á)\n",
        "        stop_words_th = set([\n",
        "            '‡πÅ‡∏ï‡πà', '‡πÅ‡∏•‡∏∞', '‡∏ó‡∏µ‡πà', '‡∏à‡∏≤‡∏Å', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏à‡∏∞', '‡∏Å‡∏±‡∏ö', '‡πÉ‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô', '‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô', '‡∏ã‡∏∂‡πà‡∏á', '‡∏ô‡∏±‡πâ‡∏ô', '‡∏´‡∏£‡∏∑‡∏≠'\n",
        "        ])  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≥ stopwords ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á\n",
        "\n",
        "        # ‡∏•‡∏ö‡∏Ñ‡∏≥ stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        words = tweet.split()\n",
        "        words = [word for word in words if word not in stop_words_th]\n",
        "\n",
        "    else:\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©\n",
        "        nltk.download('stopwords')\n",
        "        stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "        # ‡∏•‡∏ö mentions, hashtags, URLs, ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        tweet = re.sub(r'@\\w+|#\\w+|http\\S+|[^A-Za-z0-9 ]+', '', tweet)\n",
        "        tweet = tweet.lower()\n",
        "\n",
        "        # ‡∏•‡∏ö stopwords\n",
        "        words = tweet.split()\n",
        "        words = [word for word in words if word not in stop_words_en]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "# Step 2: Feature Extraction using Bag of Words, TF-IDF, Word2Vec\n",
        "def extract_features(corpus, method='bow'):\n",
        "    if method == 'bow':\n",
        "        vectorizer = CountVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    elif method == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    elif method == 'word2vec':\n",
        "        model = Word2Vec(sentences=[tweet.split() for tweet in corpus], vector_size=100, window=5, min_count=1, workers=4)\n",
        "        features = np.array([np.mean([model.wv[word] for word in tweet.split() if word in model.wv] or [np.zeros(100)], axis=0) for tweet in corpus])\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method: choose 'bow', 'tfidf', or 'word2vec'\")\n",
        "    return features\n",
        "\n",
        "\n",
        "# Step 3: Read Dataset and Apply Preprocessing & Feature Extraction\n",
        "def main(file_path, feature_method='bow'):\n",
        "    # Read the dataset\n",
        "    df = pd.read_excel(file_path, sheet_name='data')  # ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å sheet ‡∏ä‡∏∑‡πà‡∏≠ 'data'\n",
        "\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'tweetText' ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "    df['tweetText'] = df['tweetText'].fillna('')\n",
        "\n",
        "    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "    df['processed_tweet'] = df['tweetText'].apply(preprocess_tweet, language='th')\n",
        "\n",
        "    # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥\n",
        "    features = extract_features(df['processed_tweet'], method=feature_method)\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á features ‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
        "    feature_df = pd.DataFrame(features.toarray() if feature_method != 'word2vec' else features)\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£ Feature Extraction\n",
        "    print(f\"\\n‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£ Feature Extraction ({feature_method}):\")\n",
        "    print(feature_df.head(4))  # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 4 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å\n",
        "\n",
        "# Run the main function with the path to your dataset and feature extraction method\n",
        "print(\"‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Bag of Words:\")\n",
        "main('thai_text_from_hashtage.xlsx', feature_method='bow')  # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 'tfidf' ‡∏´‡∏£‡∏∑‡∏≠ 'word2vec' ‡πÑ‡∏î‡πâ\n",
        "\n",
        "print(\"\\n‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á TF-IDF:\")\n",
        "main('thai_text_from_hashtage.xlsx', feature_method='tfidf')  # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 'tfidf' ‡∏´‡∏£‡∏∑‡∏≠ 'word2vec' ‡πÑ‡∏î‡πâ\n",
        "\n",
        "print(\"\\n‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Word2Vec:\")\n",
        "main('thai_text_from_hashtage.xlsx', feature_method='word2vec')  # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 'tfidf' ‡∏´‡∏£‡∏∑‡∏≠ 'word2vec' ‡πÑ‡∏î‡πâ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhy8IuZ0XlJf",
        "outputId": "bd76112c-6b83-4d97-c554-781d3b6f6312"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Bag of Words:\n",
            "\n",
            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£ Feature Extraction (bow):\n",
            "   0     1     2     3     4     5     6     7     8     9     ...  1775  \\\n",
            "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
            "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
            "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
            "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
            "\n",
            "   1776  1777  1778  1779  1780  1781  1782  1783  1784  \n",
            "0     0     0     0     0     0     0     0     0     0  \n",
            "1     0     0     0     0     0     0     0     0     0  \n",
            "2     0     0     0     0     0     0     0     0     0  \n",
            "3     0     0     0     0     0     0     0     0     0  \n",
            "\n",
            "[4 rows x 1785 columns]\n",
            "\n",
            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á TF-IDF:\n",
            "\n",
            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£ Feature Extraction (tfidf):\n",
            "   0     1     2     3     4     5     6     7     8     9     ...  1775  \\\n",
            "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "\n",
            "   1776  1777  1778  1779  1780  1781  1782  1783  1784  \n",
            "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "\n",
            "[4 rows x 1785 columns]\n",
            "\n",
            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Word2Vec:\n",
            "\n",
            "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£ Feature Extraction (word2vec):\n",
            "         0         1         2         3         4         5         6   \\\n",
            "0 -0.012226  0.005836 -0.004231  0.006193  0.004646 -0.015305 -0.000350   \n",
            "1 -0.018868  0.013346 -0.008461  0.010369  0.005716 -0.021172  0.001838   \n",
            "2 -0.010501  0.007569 -0.006128  0.007096  0.005915 -0.013811  0.001032   \n",
            "3 -0.017601  0.006792 -0.007830  0.007910  0.003607 -0.016652  0.000598   \n",
            "\n",
            "         7         8         9   ...        90        91        92        93  \\\n",
            "0  0.016298 -0.002781  0.000047  ...  0.013224  0.006044  0.005081  0.003035   \n",
            "1  0.029175 -0.008404 -0.000581  ...  0.022953  0.010209  0.008697  0.004373   \n",
            "2  0.017115 -0.007763  0.000267  ...  0.012362  0.007645  0.004544  0.003452   \n",
            "3  0.023723 -0.006078 -0.000262  ...  0.015124  0.008797  0.008663  0.003828   \n",
            "\n",
            "         94        95        96        97        98        99  \n",
            "0  0.013581  0.008492  0.006562 -0.005382  0.000356 -0.000676  \n",
            "1  0.023881  0.013477  0.011459 -0.008308  0.000554 -0.002252  \n",
            "2  0.012993  0.009520  0.005661 -0.005777 -0.000585  0.002379  \n",
            "3  0.017478  0.010836  0.008135 -0.007673  0.001072  0.000580  \n",
            "\n",
            "[4 rows x 100 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "app.py"
      ],
      "metadata": {
        "id": "gVfbpxFTXvDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import make_pipeline\n",
        "#from wordcut import wordcut  # Thai word segmentation library\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Step 1.1: Preprocess Tweets\n",
        "def preprocess_tweet(tweet, language='en'):\n",
        "    if tweet is None:\n",
        "        return \"\"  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤ tweet ‡πÄ‡∏õ‡πá‡∏ô None\n",
        "\n",
        "    tweet = str(tweet)  # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á\n",
        "\n",
        "    if language == 'th':\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        tweet = word_tokenize(tweet)  # ‡πÉ‡∏ä‡πâ pythainlp ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "\n",
        "        # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        tweet = re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', ' '.join(tweet))  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏Å‡πà‡∏≠‡∏ô\n",
        "        tweet = tweet.lower()\n",
        "\n",
        "        # ‡πÇ‡∏´‡∏•‡∏î stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å `stopwords` ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á)\n",
        "        stop_words_th = set([\n",
        "            '‡πÅ‡∏ï‡πà', '‡πÅ‡∏•‡∏∞', '‡∏ó‡∏µ‡πà', '‡∏à‡∏≤‡∏Å', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏à‡∏∞', '‡∏Å‡∏±‡∏ö', '‡πÉ‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô', '‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô', '‡∏ã‡∏∂‡πà‡∏á', '‡∏ô‡∏±‡πâ‡∏ô', '‡∏´‡∏£‡∏∑‡∏≠'\n",
        "        ])  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≥ stopwords ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏≠‡∏á\n",
        "\n",
        "        # ‡∏•‡∏ö‡∏Ñ‡∏≥ stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        words = tweet.split()\n",
        "        words = [word for word in words if word not in stop_words_th]\n",
        "\n",
        "    else:\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©\n",
        "        nltk.download('stopwords')\n",
        "        stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "        # ‡∏•‡∏ö mentions, hashtags, URLs, ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        tweet = re.sub(r'@\\w+|#\\w+|http\\S+|[^A-Za-z0-9 ]+', '', tweet)\n",
        "        tweet = tweet.lower()\n",
        "\n",
        "        # ‡∏•‡∏ö stopwords\n",
        "        words = tweet.split()\n",
        "        words = [word for word in words if word not in stop_words_en]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "# Step 1.2: Read Dataset and Apply Preprocessing\n",
        "def main(file_path):\n",
        "    # Read the dataset\n",
        "    df = pd.read_excel(file_path, sheet_name='data')  # ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å sheet ‡∏ä‡∏∑‡πà‡∏≠ 'data'\n",
        "\n",
        "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'tweetText' ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "    df['tweetText'] = df['tweetText'].fillna('')\n",
        "\n",
        "    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "    df['processed_tweet'] = df['tweetText'].apply(preprocess_tweet, language='th')\n",
        "\n",
        "    print(df[['tweetText', 'processed_tweet']].head())  # ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Feature Extraction using Bag of Words, TF-IDF, Word2Vec\n",
        "def extract_features(corpus, method='bow'):\n",
        "    if method == 'bow':\n",
        "        vectorizer = CountVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    elif method == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    elif method == 'word2vec':\n",
        "        model = Word2Vec(sentences=[tweet.split() for tweet in corpus], vector_size=100, window=5, min_count=1, workers=4)\n",
        "        features = np.array([np.mean([model.wv[word] for word in tweet.split() if word in model.wv] or [np.zeros(100)], axis=0) for tweet in corpus])\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method: choose 'bow', 'tfidf', or 'word2vec'\")\n",
        "    return features\n",
        "\n",
        "# Step 3: Train and Evaluate Ensemble Models with Cross-Validation\n",
        "def train_and_evaluate_ensemble(features, labels, folds=[5, 10]):\n",
        "    # Use Ensemble Models such as RandomForest, Gradient Boosting, AdaBoost\n",
        "    ensemble_models = {\n",
        "        'Random Forest': RandomForestClassifier(),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(),\n",
        "        'AdaBoost': AdaBoostClassifier()\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    for fold in folds:\n",
        "        cv = KFold(n_splits=fold, shuffle=True, random_state=42)\n",
        "\n",
        "        for model_name, model in ensemble_models.items():\n",
        "            accuracy = cross_val_score(model, features, labels, cv=cv, scoring='accuracy')\n",
        "            results.append({\n",
        "                'Method': 'BoW' if fold == 5 else 'TF-IDF',  # Modify as per your extraction method\n",
        "                'Fold': fold,\n",
        "                'Model': model_name,\n",
        "                'Mean Accuracy': round(np.mean(accuracy), 4),\n",
        "                'Standard Deviation': round(np.std(accuracy), 4)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Step 4: Load Dataset from Excel\n",
        "def load_data(file_path):\n",
        "    df = pd.read_excel(file_path, sheet_name='data')\n",
        "    tweets = df['tweetText'].apply(preprocess_tweet, language='th')  # ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "    labels = df['hashtage']\n",
        "    return tweets, labels\n",
        "\n",
        "# Step 5: Main Function to Execute\n",
        "def main(file_path):\n",
        "    tweets, labels = load_data(file_path)\n",
        "\n",
        "    # Extract features using different methods\n",
        "    methods = ['bow', 'tfidf', 'word2vec']\n",
        "\n",
        "    all_results = []\n",
        "    for method in methods:\n",
        "        features = extract_features(tweets, method)\n",
        "\n",
        "        # Train and Evaluate Ensemble Models\n",
        "        results_df = train_and_evaluate_ensemble(features, labels)\n",
        "        results_df['Method'] = method\n",
        "        all_results.append(results_df)\n",
        "\n",
        "    # Combine results from all feature extraction methods\n",
        "    final_results = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "    # Show results as a DataFrame with separate fold results\n",
        "    print(final_results)\n",
        "\n",
        "# Run the main function with the path to your dataset\n",
        "main('thai_text_from_hashtage.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85CaoiE_XveZ",
        "outputId": "da09a3a6-c6bf-4b20-d82d-255c96ae2cfe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Method  Fold              Model  Mean Accuracy  Standard Deviation\n",
            "0        bow     5      Random Forest         1.0000              0.0000\n",
            "1        bow     5  Gradient Boosting         1.0000              0.0000\n",
            "2        bow     5           AdaBoost         1.0000              0.0000\n",
            "3        bow    10      Random Forest         1.0000              0.0000\n",
            "4        bow    10  Gradient Boosting         1.0000              0.0000\n",
            "5        bow    10           AdaBoost         1.0000              0.0000\n",
            "6      tfidf     5      Random Forest         1.0000              0.0000\n",
            "7      tfidf     5  Gradient Boosting         1.0000              0.0000\n",
            "8      tfidf     5           AdaBoost         0.9977              0.0047\n",
            "9      tfidf    10      Random Forest         1.0000              0.0000\n",
            "10     tfidf    10  Gradient Boosting         1.0000              0.0000\n",
            "11     tfidf    10           AdaBoost         1.0000              0.0000\n",
            "12  word2vec     5      Random Forest         0.9789              0.0088\n",
            "13  word2vec     5  Gradient Boosting         0.9790              0.0200\n",
            "14  word2vec     5           AdaBoost         0.9696              0.0057\n",
            "15  word2vec    10      Random Forest         0.9860              0.0114\n",
            "16  word2vec    10  Gradient Boosting         0.9790              0.0264\n",
            "17  word2vec    10           AdaBoost         0.9579              0.0310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "thai_sentiment"
      ],
      "metadata": {
        "id": "OGNNRwuw3ODc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mZj5psJ_DEC",
        "outputId": "a08b260e-4db5-4154-e82f-6c26073cc5b0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Thai_Sentiment.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1_fRL5KqoIq1GNuunJOOyXBs7oe5uL6wt\n",
        "\"\"\"\n",
        "\n",
        "!pip install pythainlp\n",
        "\n",
        "\n",
        "\"\"\"# ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics import classification_report\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Step 1: Preprocess Text\n",
        "def preprocess_text(text, language='th'):\n",
        "    if text is None:\n",
        "        return \"\"  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤ text ‡πÄ‡∏õ‡πá‡∏ô None\n",
        "\n",
        "    text = str(text)  # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á\n",
        "\n",
        "    if language == 'th':\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        text = word_tokenize(text)  # ‡πÉ‡∏ä‡πâ pythainlp ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "\n",
        "        # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        text = re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', ' '.join(text))\n",
        "        text = text.lower()\n",
        "\n",
        "        # ‡∏•‡∏ö stopwords ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "        stop_words_th = set(['‡πÅ‡∏ï‡πà', '‡πÅ‡∏•‡∏∞', '‡∏ó‡∏µ‡πà', '‡∏à‡∏≤‡∏Å', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏à‡∏∞', '‡∏Å‡∏±‡∏ö', '‡πÉ‡∏ô', '‡πÑ‡∏î‡πâ', '‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô', '‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô', '‡∏ã‡∏∂‡πà‡∏á', '‡∏ô‡∏±‡πâ‡∏ô', '‡∏´‡∏£‡∏∑‡∏≠'])\n",
        "        words = text.split()\n",
        "        words = [word for word in words if word not in stop_words_th]\n",
        "    else:\n",
        "        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©\n",
        "        nltk.download('stopwords')\n",
        "        stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "        # ‡∏•‡∏ö mentions, hashtags, URLs, ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "        text = re.sub(r'@\\w+|#\\w+|http\\S+|[^A-Za-z0-9 ]+', '', text)\n",
        "        text = text.lower()\n",
        "\n",
        "        # ‡∏•‡∏ö stopwords\n",
        "        words = text.split()\n",
        "        words = [word for word in words if word not in stop_words_en]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Step 2: Load Dataset\n",
        "def load_data(file_path):\n",
        "    df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
        "    df['Text'] = df['Text'].fillna('')\n",
        "    df['processed_text'] = df['Text'].apply(preprocess_text, language='th')\n",
        "    labels = df['Class']\n",
        "    return df['processed_text'], labels\n",
        "\n",
        "# Step 3: Feature Extraction\n",
        "def extract_features(corpus, method='bow'):\n",
        "    if method == 'bow':\n",
        "        vectorizer = CountVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    elif method == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    elif method == 'word2vec':\n",
        "        model = Word2Vec(sentences=[text.split() for text in corpus], vector_size=100, window=5, min_count=1, workers=4)\n",
        "        features = np.array([np.mean([model.wv[word] for word in text.split() if word in model.wv] or [np.zeros(100)], axis=0) for text in corpus])\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method: choose 'bow', 'tfidf', or 'word2vec'\")\n",
        "    return features\n",
        "\n",
        "# Step 4: Train and Evaluate\n",
        "def train_and_evaluate_ensemble(features, labels, folds=5):\n",
        "    models = {\n",
        "        'Random Forest': RandomForestClassifier(),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(),\n",
        "        'AdaBoost': AdaBoostClassifier()\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    cv = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        accuracy = cross_val_score(model, features, labels, cv=cv, scoring='accuracy')\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Mean Accuracy': round(np.mean(accuracy), 4),\n",
        "            'Standard Deviation': round(np.std(accuracy), 4)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Step 5: Main Function\n",
        "def main(file_path):\n",
        "    texts, labels = load_data(file_path)\n",
        "\n",
        "    # Feature Extraction\n",
        "    methods = ['bow', 'tfidf', 'word2vec']\n",
        "    all_results = []\n",
        "\n",
        "    for method in methods:\n",
        "        features = extract_features(texts, method)\n",
        "        results_df = train_and_evaluate_ensemble(features, labels)\n",
        "        results_df['Method'] = method\n",
        "        all_results.append(results_df)\n",
        "\n",
        "    final_results = pd.concat(all_results, ignore_index=True)\n",
        "    print(final_results)\n",
        "\n",
        "# Execute\n",
        "main('Thai_Sentiment.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ7Y6USa_mL9",
        "outputId": "60a3ae12-bc9b-46e1-eb1b-48954c150c50"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.11/dist-packages (5.0.5)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (2024.12.14)\n",
            "               Model  Mean Accuracy  Standard Deviation    Method\n",
            "0      Random Forest         0.8247              0.0087       bow\n",
            "1  Gradient Boosting         0.7238              0.0262       bow\n",
            "2           AdaBoost         0.6674              0.0363       bow\n",
            "3      Random Forest         0.8285              0.0106     tfidf\n",
            "4  Gradient Boosting         0.7222              0.0270     tfidf\n",
            "5           AdaBoost         0.6685              0.0368     tfidf\n",
            "6      Random Forest         0.8307              0.0251  word2vec\n",
            "7  Gradient Boosting         0.8077              0.0157  word2vec\n",
            "8           AdaBoost         0.6438              0.0303  word2vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest_word2vec"
      ],
      "metadata": {
        "id": "Bk9S1uDEISCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "def preprocess_text(text):\n",
        "    if text is None:\n",
        "        return \"\"  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô None\n",
        "\n",
        "    text = str(text)  # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á\n",
        "    words = word_tokenize(text)  # ‡πÉ‡∏ä‡πâ pythainlp ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "    text = ' '.join(words)  # ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
        "    text = re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', text)  # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "    return text\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ Word2Vec\n",
        "def extract_features_word2vec(corpus):\n",
        "    model = Word2Vec(sentences=[text.split() for text in corpus], vector_size=100, window=5, min_count=1, workers=4)\n",
        "    features = np.array([\n",
        "        np.mean([model.wv[word] for word in text.split() if word in model.wv] or [np.zeros(100)], axis=0)\n",
        "        for text in corpus\n",
        "    ])\n",
        "    return features, model\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "def train_and_save_model(features, labels, save_path='random_forest_model.pkl'):\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(features, labels)\n",
        "\n",
        "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ pickle\n",
        "    with open(save_path, 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "    return model\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "def test_model(test_texts, w2v_model, loaded_model):\n",
        "    processed_texts = [preprocess_text(text) for text in test_texts]\n",
        "    test_features = np.array([\n",
        "        np.mean([w2v_model.wv[word] for word in text.split() if word in w2v_model.wv] or [np.zeros(100)], axis=0)\n",
        "        for text in processed_texts\n",
        "    ])\n",
        "    predictions = loaded_model.predict(test_features)\n",
        "    return predictions\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "def main(file_path):\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel\n",
        "    df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
        "    df['Text'] = df['Text'].fillna('').apply(preprocess_text)  # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "\n",
        "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î Train ‡πÅ‡∏•‡∏∞ Test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Class'], test_size=0.2, random_state=42)\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ Word2Vec\n",
        "    train_features, w2v_model = extract_features_word2vec(X_train)\n",
        "\n",
        "    # ‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "    model = train_and_save_model(train_features, y_train)\n",
        "\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
        "    with open('random_forest_model.pkl', 'rb') as file:\n",
        "        loaded_model = pickle.load(file)\n",
        "\n",
        "    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "    predictions = test_model(X_test, w2v_model, loaded_model)\n",
        "    print(\"Predictions:\", predictions)\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô\n",
        "    accuracy = np.mean(predictions == y_test)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á Classification Report ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° 4 ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á\n",
        "    print(\"Classification Report:\")\n",
        "    report = classification_report(y_test, predictions, output_dict=True)\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô classification report ‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
        "    report_df = pd.DataFrame(report).T\n",
        "\n",
        "    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° 4 ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á\n",
        "    report_df = report_df.round(4)\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á\n",
        "    print(report_df)\n",
        "\n",
        "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "main('Thai_Sentiment.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ChCt8I8_vKB",
        "outputId": "aacec8d5-e2c1-4fc4-8b16-52da428cd00c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to random_forest_model.pkl\n",
            "Predictions: ['negative' 'negative' 'negative' 'negative' 'swear' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'positive' 'positive' 'negative' 'swear' 'positive'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'positive' 'positive' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'positive' 'positive'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'positive' 'negative' 'positive'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'positive' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'swear' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'swear' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'positive'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive' 'swear'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'swear' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
            " 'negative' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative']\n",
            "Accuracy: 0.8164\n",
            "Classification Report:\n",
            "              precision  recall  f1-score   support\n",
            "negative         0.7886  0.9833    0.8752  239.0000\n",
            "positive         1.0000  0.5545    0.7135  110.0000\n",
            "swear            0.3333  0.1250    0.1818   16.0000\n",
            "accuracy         0.8164  0.8164    0.8164    0.8164\n",
            "macro avg        0.7073  0.5543    0.5902  365.0000\n",
            "weighted avg     0.8323  0.8164    0.7961  365.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Test by New data\"\"\"\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "def preprocess_text(text):\n",
        "    return re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', ' '.join(word_tokenize(str(text or \"\"))))\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ Word2Vec\n",
        "def extract_features_word2vec(corpus):\n",
        "    model = Word2Vec(sentences=[text.split() for text in corpus], vector_size=100, window=5, min_count=1, workers=4)\n",
        "    features = np.array([np.mean([model.wv[w] for w in text.split() if w in model.wv] or [np.zeros(100)], axis=0) for text in corpus])\n",
        "    return features, model\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "def train_and_save_model(features, labels, model_path='random_forest_model.pkl'):\n",
        "    model = RandomForestClassifier().fit(features, labels)\n",
        "    with open(model_path, 'wb') as f: pickle.dump(model, f)\n",
        "    return model\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "def predict_new_data(new_data, w2v_model, model_path='random_forest_model.pkl'):\n",
        "    features = np.array([np.mean([w2v_model.wv[w] for w in preprocess_text(text).split() if w in w2v_model.wv] or [np.zeros(100)], axis=0) for text in new_data])\n",
        "    with open(model_path, 'rb') as f: model = pickle.load(f)\n",
        "    return model.predict(features)\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "def main(file_path):\n",
        "    df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
        "    df['Text'] = df['Text'].fillna('').apply(preprocess_text)\n",
        "    features, w2v_model = extract_features_word2vec(df['Text'])\n",
        "    train_and_save_model(features, df['Class'])\n",
        "\n",
        "    while True:\n",
        "        text = input(\"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å): \")\n",
        "        if text.lower() == 'exit': break\n",
        "        print(f\"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {predict_new_data([text], w2v_model)[0]}\")\n",
        "\n",
        "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "main('Thai_Sentiment.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QJi25DL0oaF",
        "outputId": "cff40e95-7658-49ca-a7cb-cfde02c29297"
      },
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å): ‡∏â‡∏±‡∏ô‡∏£‡∏±‡∏Å‡πÄ‡∏ò‡∏≠\n",
            "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: positive\n",
            "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Random Forest TF-IDF]"
      ],
      "metadata": {
        "id": "ve-0YzidIZ9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "def preprocess_text(text):\n",
        "    if text is None:\n",
        "        return \"\"  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô None\n",
        "\n",
        "    text = str(text)  # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á\n",
        "    words = word_tokenize(text)  # ‡πÉ‡∏ä‡πâ pythainlp ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "    text = ' '.join(words)  # ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
        "    text = re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', text)  # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "    return text\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ TF-IDF\n",
        "def extract_features_tfidf(corpus):\n",
        "    vectorizer = TfidfVectorizer(max_features=1000)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
        "    features = vectorizer.fit_transform(corpus)\n",
        "    return features, vectorizer\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "def train_and_save_model(features, labels, save_path='random_forest_tfidf_model.pkl'):\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(features, labels)\n",
        "\n",
        "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ pickle\n",
        "    with open(save_path, 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "    return model\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "def test_model(test_features, loaded_model):\n",
        "    predictions = loaded_model.predict(test_features)\n",
        "    return predictions\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "def main(file_path):\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel\n",
        "    df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
        "    df['Text'] = df['Text'].fillna('').apply(preprocess_text)  # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "\n",
        "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î Train ‡πÅ‡∏•‡∏∞ Test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Class'], test_size=0.2, random_state=42)\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ TF-IDF\n",
        "    train_features, tfidf_vectorizer = extract_features_tfidf(X_train)\n",
        "\n",
        "    # ‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "    model = train_and_save_model(train_features, y_train)\n",
        "\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
        "    with open('random_forest_tfidf_model.pkl', 'rb') as file:\n",
        "        loaded_model = pickle.load(file)\n",
        "\n",
        "    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "    test_features = tfidf_vectorizer.transform(X_test)\n",
        "    predictions = test_model(test_features, loaded_model)\n",
        "    print(\"Predictions:\", predictions)\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô\n",
        "    accuracy = np.mean(predictions == y_test)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á Classification Report ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° 4 ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á\n",
        "    print(\"Classification Report:\")\n",
        "    report = classification_report(y_test, predictions, output_dict=True)\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô classification report ‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
        "    report_df = pd.DataFrame(report).T\n",
        "\n",
        "    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏° 4 ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á\n",
        "    report_df = report_df.round(4)\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á\n",
        "    print(report_df)\n",
        "\n",
        "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "main('Thai_Sentiment.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9kn90AjIf1X",
        "outputId": "bdd906fe-df50-41c5-b960-178b8ac1dc80"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to random_forest_tfidf_model.pkl\n",
            "Predictions: ['negative' 'negative' 'negative' 'negative' 'swear' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'positive' 'negative' 'positive' 'positive' 'negative' 'swear' 'positive'\n",
            " 'negative' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'negative' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
            " 'positive' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'swear' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'positive' 'positive' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'positive' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'positive' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'swear' 'negative'\n",
            " 'negative' 'negative' 'negative' 'swear' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'positive' 'positive' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'swear' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
            " 'negative' 'negative' 'negative' 'swear' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'positive' 'positive' 'negative' 'positive' 'negative' 'positive'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'swear' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
            " 'positive' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative']\n",
            "Accuracy: 0.8110\n",
            "Classification Report:\n",
            "              precision  recall  f1-score  support\n",
            "negative         0.8021  0.9498    0.8697  239.000\n",
            "positive         0.8784  0.5909    0.7065  110.000\n",
            "swear            0.5000  0.2500    0.3333   16.000\n",
            "accuracy         0.8110  0.8110    0.8110    0.811\n",
            "macro avg        0.7268  0.5969    0.6365  365.000\n",
            "weighted avg     0.8119  0.8110    0.7970  365.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Test by New data\"\"\"\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "def preprocess_text(text):\n",
        "    return re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', ' '.join(word_tokenize(str(text or \"\"))))\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ TF-IDF\n",
        "def extract_features_tfidf(corpus):\n",
        "    vectorizer = TfidfVectorizer(max_features=1000)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà 1000\n",
        "    features = vectorizer.fit_transform(corpus)\n",
        "    return features, vectorizer\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "def train_and_save_model(features, labels, model_path='random_forest_tfidf_model.pkl'):\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(features, labels)\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "    return model\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "def predict_new_data(new_data, tfidf_vectorizer, model_path='random_forest_tfidf_model.pkl'):\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ TF-IDF\n",
        "    features = tfidf_vectorizer.transform([preprocess_text(text) for text in new_data])\n",
        "    with open(model_path, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    return model.predict(features)\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "def main(file_path):\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "    df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
        "    df['Text'] = df['Text'].fillna('').apply(preprocess_text)\n",
        "\n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ TF-IDF\n",
        "    features, tfidf_vectorizer = extract_features_tfidf(df['Text'])\n",
        "\n",
        "    # ‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "    train_and_save_model(features, df['Class'])\n",
        "\n",
        "    # ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "    while True:\n",
        "        text = input(\"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å): \")\n",
        "        if text.lower() == 'exit':\n",
        "            break\n",
        "        prediction = predict_new_data([text], tfidf_vectorizer)\n",
        "        print(f\"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {prediction[0]}\")\n",
        "\n",
        "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "main('Thai_Sentiment.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN1JFkUZI9PF",
        "outputId": "27b071dd-87e1-4949-b454-5d295d07b98a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to random_forest_tfidf_model.pkl\n",
            "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å): ‡∏â‡∏±‡∏ô‡∏£‡∏±‡∏Å‡πÄ‡∏ò‡∏≠\n",
            "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: negative\n",
            "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting ‡πÅ‡∏ö‡∏ö word2vec"
      ],
      "metadata": {
        "id": "uwxgSCdZJ76e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Gradient Boosting with Word2Vec and Classification Report\"\"\"\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "def preprocess_text(text):\n",
        "    return re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', ' '.join(word_tokenize(str(text or \"\"))))\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ Word2Vec\n",
        "def extract_features_word2vec(corpus):\n",
        "    model = Word2Vec(sentences=[text.split() for text in corpus], vector_size=100, window=5, min_count=1, workers=4)\n",
        "    features = np.array([\n",
        "        np.mean([model.wv[word] for word in text.split() if word in model.wv] or [np.zeros(100)], axis=0)\n",
        "        for text in corpus\n",
        "    ])\n",
        "    return features, model\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "def train_and_save_model(features, labels, model_path='gradient_boosting_model.pkl'):\n",
        "    model = GradientBoostingClassifier(random_state=42)\n",
        "    model.fit(features, labels)\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "    return model\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "def main(file_path):\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "    df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
        "    df['Text'] = df['Text'].fillna('').apply(preprocess_text)\n",
        "\n",
        "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î Train ‡πÅ‡∏•‡∏∞ Test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Class'], test_size=0.2, random_state=42)\n",
        "\n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ Word2Vec\n",
        "    train_features, w2v_model = extract_features_word2vec(X_train)\n",
        "    test_features = np.array([\n",
        "        np.mean([w2v_model.wv[word] for word in text.split() if word in w2v_model.wv] or [np.zeros(100)], axis=0)\n",
        "        for text in X_test\n",
        "    ])\n",
        "\n",
        "    # ‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "    train_and_save_model(train_features, y_train)\n",
        "\n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ù‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
        "    with open('gradient_boosting_model.pkl', 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "    # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
        "    predictions = model.predict(test_features)\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    report = classification_report(y_test, predictions, digits=4)\n",
        "    print(report)\n",
        "\n",
        "\n",
        "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å\n",
        "main('Thai_Sentiment.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErMgX85DJ9Jo",
        "outputId": "4e6aec28-2f17-4880-9968-0746d4c553b3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to gradient_boosting_model.pkl\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.8913    0.6862    0.7754       239\n",
            "    positive     1.0000    0.5091    0.6747       110\n",
            "       swear     0.0480    0.3750    0.0851        16\n",
            "\n",
            "    accuracy                         0.6192       365\n",
            "   macro avg     0.6464    0.5234    0.5117       365\n",
            "weighted avg     0.8871    0.6192    0.7148       365\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "deploy 1 g per model"
      ],
      "metadata": {
        "id": "5KpZ-4vl33T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"DeployTextModel.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1xAycJeCrmy2fdVjL67SiSwkxQeWEzLzh\n",
        "\n",
        "# Install\n",
        "\"\"\"\n",
        "\n",
        "# ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ ngrok.com\n",
        "!pip install flask flask-ngrok gensim pythainlp scikit-learn pandas numpy openpyxl\n",
        "\n",
        "!pip install matplotlib flask flask-ngrok\n",
        "\n",
        "!pip install pyngrok\n",
        "\n",
        "!npm install -g localtunnel\n",
        "\n",
        "#authtoken ‡∏Ç‡∏≠‡∏á‡πÉ‡∏Ñ‡∏£‡∏Ç‡∏≠‡∏á‡∏°‡∏±‡∏ô‡∏à‡πä‡∏∞\n",
        "!ngrok authtoken 2s0bI5hhFxx5wZZNVs3QNXwLsDv_88bEHUWGaWLrJKvUZpFxr\n",
        "\n",
        "!pip install matplotlib\n",
        "\n",
        "\"\"\"# ‡πÄ‡∏õ‡∏¥‡∏î tunnel ‡∏Ç‡∏≠‡∏á ngrok\"\"\"\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ tunnel ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "existing_tunnels = ngrok.get_tunnels()\n",
        "if not existing_tunnels:\n",
        "    public_url = ngrok.connect(5000)  # ‡πÄ‡∏õ‡∏¥‡∏î tunnel ‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "else:\n",
        "    print(\"Existing Tunnel:\", existing_tunnels[0].public_url)  # ‡πÉ‡∏ä‡πâ tunnel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà\n",
        "\n",
        "\"\"\"# ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡πÅ‡∏•‡∏∞ Report\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "from flask import Flask, request, render_template_string, send_file\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "import re\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import os\n",
        "import signal\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "def preprocess_text(text):\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    words = word_tokenize(text)\n",
        "    text = ' '.join(words)\n",
        "    text = re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå TF-IDF\n",
        "def extract_features_tfidf(corpus, vectorizer=None):\n",
        "    if vectorizer is None:\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    else:\n",
        "        features = vectorizer.transform(corpus)\n",
        "    return features, vectorizer\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå Word2Vec\n",
        "def extract_features_word2vec(corpus, w2v_model):\n",
        "    return np.array([np.mean([w2v_model.wv[word] for word in text.split() if word in w2v_model.wv] or [np.zeros(100)], axis=0) for text in corpus])\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
        "def save_to_file(input_text, predictions):\n",
        "    with open(\"analysis_results.txt\", \"a\", encoding=\"utf-8\") as file:\n",
        "        file.write(f\"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {input_text}\\n\")\n",
        "        for model_name, prediction in predictions.items():\n",
        "            file.write(f\"{model_name}: {prediction}\\n\")\n",
        "        file.write(\"\\n\")\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå Flask\n",
        "def shutdown_server():\n",
        "    os.kill(os.getpid(), signal.SIGINT)\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "df = pd.read_excel('Thai_Sentiment.xlsx')\n",
        "df['Text'] = df['Text'].apply(preprocess_text)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Word2Vec ‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "w2v_model = Word2Vec(sentences=[text.split() for text in df['Text']], vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á TF-IDF ‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "tfidf_features, tfidf_vectorizer = extract_features_tfidf(df['Text'])\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
        "with open('random_forest_model.pkl', 'rb') as file:\n",
        "    rf_word2vec = pickle.load(file)\n",
        "\n",
        "with open('random_forest_tfidf_model.pkl', 'rb') as file:\n",
        "    rf_tfidf = pickle.load(file)\n",
        "\n",
        "with open('gradient_boosting_model.pkl', 'rb') as file:\n",
        "    gb_word2vec = pickle.load(file)\n",
        "\n",
        "def plot_bar_chart_per_model(sentiment_counts, model_name):\n",
        "    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "\n",
        "    # ‡πÅ‡∏¢‡∏Å‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "    ax.bar(['Positive', 'Negative', 'Swear'], [\n",
        "        sentiment_counts[model_name]['positive'],\n",
        "        sentiment_counts[model_name]['negative'],\n",
        "        sentiment_counts[model_name]['swear']\n",
        "    ], color=['blue', 'red', 'green'])\n",
        "\n",
        "    ax.set_ylabel('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô')\n",
        "    ax.set_title(f'‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}')\n",
        "    ax.set_xticks(['Positive', 'Negative', 'Swear'])\n",
        "\n",
        "    # Save bar chart to a BytesIO object and return the image\n",
        "    img = BytesIO()\n",
        "    plt.savefig(img, format='png')\n",
        "    img.seek(0)\n",
        "    return img\n",
        "\n",
        "\n",
        "def count_sentiment_types(file_path, model_names):\n",
        "    sentiment_counts = {model: {'positive': 0, 'negative': 0, 'swear': 0} for model in model_names}\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for i in range(0, len(lines), 3):\n",
        "        result_line = lines[i + 1]\n",
        "        for model_name in model_names:\n",
        "            if model_name in result_line:\n",
        "                if 'swear' in result_line:\n",
        "                    sentiment_counts[model_name]['swear'] += 1\n",
        "                elif 'positive' in result_line:\n",
        "                    sentiment_counts[model_name]['positive'] += 1\n",
        "                elif 'negative' in result_line:\n",
        "                    sentiment_counts[model_name]['negative'] += 1\n",
        "\n",
        "    return sentiment_counts\n",
        "\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Flask App\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template_string('''\n",
        "        <h1>Thai Sentiment Analysis</h1>\n",
        "        <form method=\"POST\" action=\"/predict\">\n",
        "            <label>‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢:</label><br>\n",
        "            <input type=\"text\" name=\"text\" style=\"width: 300px;\"><br><br>\n",
        "            <input type=\"submit\" value=\"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå\">\n",
        "        </form>\n",
        "        <br>\n",
        "        <a href=\"/result\">‡∏î‡∏π‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î</a><br><br>\n",
        "        <form method=\"POST\" action=\"/shutdown\">\n",
        "            <input type=\"submit\" value=\"‡∏õ‡∏¥‡∏î‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå\">\n",
        "        </form>\n",
        "    ''')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    user_text = request.form['text']\n",
        "    processed_text = preprocess_text(user_text)\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå\n",
        "    word2vec_features = extract_features_word2vec([processed_text], w2v_model)\n",
        "    tfidf_features, _ = extract_features_tfidf([processed_text], tfidf_vectorizer)\n",
        "\n",
        "    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á 3\n",
        "    rf_word2vec_prediction = rf_word2vec.predict(word2vec_features)[0]\n",
        "    rf_tfidf_prediction = rf_tfidf.predict(tfidf_features)[0]\n",
        "    gb_word2vec_prediction = gb_word2vec.predict(word2vec_features)[0]\n",
        "\n",
        "    # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "    predictions = {\n",
        "        \"Random Forest (Word2Vec)\": rf_word2vec_prediction,\n",
        "        \"Random Forest (TF-IDF)\": rf_tfidf_prediction,\n",
        "        \"Gradient Boosting (Word2Vec)\": gb_word2vec_prediction\n",
        "    }\n",
        "\n",
        "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
        "    save_to_file(user_text, predictions)\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "    result_html = ''.join([f\"<p>{model}: {pred}</p>\" for model, pred in predictions.items()])\n",
        "    return f\"<h3>‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:</h3>{result_html}<br><a href='/'>‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å</a>\"\n",
        "\n",
        "@app.route('/result')\n",
        "def result():\n",
        "    # ‡∏ô‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå\n",
        "    model_names = [\"Random Forest (Word2Vec)\", \"Random Forest (TF-IDF)\", \"Gradient Boosting (Word2Vec)\"]\n",
        "    sentiment_counts = count_sentiment_types('analysis_results.txt', model_names)\n",
        "\n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "    img_base64_list = []\n",
        "    for model_name in model_names:\n",
        "        img = plot_bar_chart_per_model(sentiment_counts, model_name)\n",
        "\n",
        "        # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô base64 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô HTML\n",
        "        img_base64 = base64.b64encode(img.getvalue()).decode('utf-8')\n",
        "        img_base64_list.append(img_base64)\n",
        "\n",
        "    return render_template_string('''\n",
        "        <h1>‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î</h1>\n",
        "        {% for img_data in img_data_list %}\n",
        "            <img src=\"data:image/png;base64,{{ img_data }}\" alt=\"Bar Chart\"><br><br>\n",
        "        {% endfor %}\n",
        "        <a href=\"/\">‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å</a>\n",
        "    ''', img_data_list=img_base64_list)\n",
        "\n",
        "\n",
        "@app.route('/shutdown', methods=['POST'])\n",
        "def shutdown():\n",
        "    shutdown_server()\n",
        "    return 'Server shutting down...'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "38EgBEDZ3147",
        "outputId": "74ffd508-045a-43e6-bd4f-9bdb1ba2c7aa"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.11/dist-packages (5.0.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "changed 22 packages in 4s\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0KAuthtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Public URL: NgrokTunnel: \"https://a2bc-34-125-197-63.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://a2bc-34-125-197-63.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:17:37] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:17:38] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:17:40] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:17:41] \"GET / HTTP/1.1\" 200 -\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3592 (\\N{THAI CHARACTER CHO CHAN}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3635 (\\N{THAI CHARACTER SARA AM}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3609 (\\N{THAI CHARACTER NO NU}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3623 (\\N{THAI CHARACTER WO WAEN}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3612 (\\N{THAI CHARACTER PHO PHUNG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3621 (\\N{THAI CHARACTER LO LING}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3585 (\\N{THAI CHARACTER KO KAI}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3634 (\\N{THAI CHARACTER SARA AA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3619 (\\N{THAI CHARACTER RO RUA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3636 (\\N{THAI CHARACTER SARA I}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3648 (\\N{THAI CHARACTER SARA E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3588 (\\N{THAI CHARACTER KHO KHWAI}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3632 (\\N{THAI CHARACTER SARA A}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3627 (\\N{THAI CHARACTER HO HIP}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3660 (\\N{THAI CHARACTER THANTHAKHAT}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3650 (\\N{THAI CHARACTER SARA O}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3617 (\\N{THAI CHARACTER MO MA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-66-5430843b6538>:129: UserWarning: Glyph 3604 (\\N{THAI CHARACTER DO DEK}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:17:43] \"GET /result HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3592 (\\N{THAI CHARACTER CHO CHAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3635 (\\N{THAI CHARACTER SARA AM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3609 (\\N{THAI CHARACTER NO NU}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3623 (\\N{THAI CHARACTER WO WAEN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3612 (\\N{THAI CHARACTER PHO PHUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3621 (\\N{THAI CHARACTER LO LING}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3585 (\\N{THAI CHARACTER KO KAI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3634 (\\N{THAI CHARACTER SARA AA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3619 (\\N{THAI CHARACTER RO RUA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3636 (\\N{THAI CHARACTER SARA I}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3648 (\\N{THAI CHARACTER SARA E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3588 (\\N{THAI CHARACTER KHO KHWAI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3632 (\\N{THAI CHARACTER SARA A}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3627 (\\N{THAI CHARACTER HO HIP}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3660 (\\N{THAI CHARACTER THANTHAKHAT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3650 (\\N{THAI CHARACTER SARA O}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3617 (\\N{THAI CHARACTER MO MA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3604 (\\N{THAI CHARACTER DO DEK}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "deploy 1g per 3 model"
      ],
      "metadata": {
        "id": "Avb6FoapbQZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"DeployTextModel.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1xAycJeCrmy2fdVjL67SiSwkxQeWEzLzh\n",
        "\n",
        "# Install\n",
        "\"\"\"\n",
        "\n",
        "# ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ ngrok.com\n",
        "!pip install flask flask-ngrok gensim pythainlp scikit-learn pandas numpy openpyxl\n",
        "\n",
        "!pip install matplotlib flask flask-ngrok\n",
        "\n",
        "!pip install pyngrok\n",
        "\n",
        "!npm install -g localtunnel\n",
        "\n",
        "#authtoken ‡∏Ç‡∏≠‡∏á‡πÉ‡∏Ñ‡∏£‡∏Ç‡∏≠‡∏á‡∏°‡∏±‡∏ô‡∏à‡πä‡∏∞\n",
        "!ngrok authtoken 2s0bI5hhFxx5wZZNVs3QNXwLsDv_88bEHUWGaWLrJKvUZpFxr\n",
        "\n",
        "!pip install matplotlib\n",
        "\n",
        "\"\"\"# ‡πÄ‡∏õ‡∏¥‡∏î tunnel ‡∏Ç‡∏≠‡∏á ngrok\"\"\"\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ tunnel ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "existing_tunnels = ngrok.get_tunnels()\n",
        "if not existing_tunnels:\n",
        "    public_url = ngrok.connect(5000)  # ‡πÄ‡∏õ‡∏¥‡∏î tunnel ‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ\n",
        "    print(f\"Public URL: {public_url}\")\n",
        "else:\n",
        "    print(\"Existing Tunnel:\", existing_tunnels[0].public_url)  # ‡πÉ‡∏ä‡πâ tunnel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà\n",
        "\n",
        "\"\"\"# ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡πÅ‡∏•‡∏∞ Report\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "from flask import Flask, request, render_template_string, send_file\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "import re\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import os\n",
        "import signal\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
        "def preprocess_text(text):\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    words = word_tokenize(text)\n",
        "    text = ' '.join(words)\n",
        "    text = re.sub(r'[^‡∏Å-‡πôa-zA-Z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå TF-IDF\n",
        "def extract_features_tfidf(corpus, vectorizer=None):\n",
        "    if vectorizer is None:\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        features = vectorizer.fit_transform(corpus)\n",
        "    else:\n",
        "        features = vectorizer.transform(corpus)\n",
        "    return features, vectorizer\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå Word2Vec\n",
        "def extract_features_word2vec(corpus, w2v_model):\n",
        "    return np.array([np.mean([w2v_model.wv[word] for word in text.split() if word in w2v_model.wv] or [np.zeros(100)], axis=0) for text in corpus])\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
        "def save_to_file(input_text, predictions):\n",
        "    with open(\"analysis_results.txt\", \"a\", encoding=\"utf-8\") as file:\n",
        "        file.write(f\"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {input_text}\\n\")\n",
        "        for model_name, prediction in predictions.items():\n",
        "            file.write(f\"{model_name}: {prediction}\\n\")\n",
        "        file.write(\"\\n\")\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå Flask\n",
        "def shutdown_server():\n",
        "    os.kill(os.getpid(), signal.SIGINT)\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "df = pd.read_excel('Thai_Sentiment.xlsx')\n",
        "df['Text'] = df['Text'].apply(preprocess_text)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Word2Vec ‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "w2v_model = Word2Vec(sentences=[text.split() for text in df['Text']], vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á TF-IDF ‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "tfidf_features, tfidf_vectorizer = extract_features_tfidf(df['Text'])\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ\n",
        "with open('random_forest_model.pkl', 'rb') as file:\n",
        "    rf_word2vec = pickle.load(file)\n",
        "\n",
        "with open('random_forest_tfidf_model.pkl', 'rb') as file:\n",
        "    rf_tfidf = pickle.load(file)\n",
        "\n",
        "with open('gradient_boosting_model.pkl', 'rb') as file:\n",
        "    gb_word2vec = pickle.load(file)\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á (Bar Chart)\n",
        "def plot_bar_chart(sentiment_counts):\n",
        "    labels = sentiment_counts.keys()\n",
        "    values = sentiment_counts.values()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.bar(labels, values, color=['blue', 'green', 'red'])\n",
        "    ax.set_ylabel('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô')\n",
        "    ax.set_title('‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå (Sentiment Analysis Results)')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    # Save bar chart to a BytesIO object and return the image\n",
        "    img = BytesIO()\n",
        "    plt.savefig(img, format='png')\n",
        "    img.seek(0)\n",
        "    return img\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå\n",
        "def count_sentiment_types(file_path):\n",
        "    sentiment_counts = {'swear': 0, 'positive': 0, 'negative': 0}\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for i in range(0, len(lines), 3):\n",
        "        result_line = lines[i + 1]\n",
        "        if 'swear' in result_line:\n",
        "            sentiment_counts['swear'] += 1\n",
        "        elif 'positive' in result_line:\n",
        "            sentiment_counts['positive'] += 1\n",
        "        elif 'negative' in result_line:\n",
        "            sentiment_counts['negative'] += 1\n",
        "\n",
        "    return sentiment_counts\n",
        "\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Flask App\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template_string('''\n",
        "        <h1>Thai Sentiment Analysis</h1>\n",
        "        <form method=\"POST\" action=\"/predict\">\n",
        "            <label>‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢:</label><br>\n",
        "            <input type=\"text\" name=\"text\" style=\"width: 300px;\"><br><br>\n",
        "            <input type=\"submit\" value=\"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå\">\n",
        "        </form>\n",
        "        <br>\n",
        "        <a href=\"/result\">‡∏î‡∏π‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î</a><br><br>\n",
        "        <form method=\"POST\" action=\"/shutdown\">\n",
        "            <input type=\"submit\" value=\"‡∏õ‡∏¥‡∏î‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå\">\n",
        "        </form>\n",
        "    ''')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    user_text = request.form['text']\n",
        "    processed_text = preprocess_text(user_text)\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå\n",
        "    word2vec_features = extract_features_word2vec([processed_text], w2v_model)\n",
        "    tfidf_features, _ = extract_features_tfidf([processed_text], tfidf_vectorizer)\n",
        "\n",
        "    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á 3\n",
        "    rf_word2vec_prediction = rf_word2vec.predict(word2vec_features)[0]\n",
        "    rf_tfidf_prediction = rf_tfidf.predict(tfidf_features)[0]\n",
        "    gb_word2vec_prediction = gb_word2vec.predict(word2vec_features)[0]\n",
        "\n",
        "    # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "    predictions = {\n",
        "        \"Random Forest (Word2Vec)\": rf_word2vec_prediction,\n",
        "        \"Random Forest (TF-IDF)\": rf_tfidf_prediction,\n",
        "        \"Gradient Boosting (Word2Vec)\": gb_word2vec_prediction\n",
        "    }\n",
        "\n",
        "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
        "    save_to_file(user_text, predictions)\n",
        "\n",
        "    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
        "    result_html = ''.join([f\"<p>{model}: {pred}</p>\" for model, pred in predictions.items()])\n",
        "    return f\"<h3>‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:</h3>{result_html}<br><a href='/'>‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å</a>\"\n",
        "\n",
        "@app.route('/result')\n",
        "def result():\n",
        "    # ‡∏ô‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå\n",
        "    sentiment_counts = count_sentiment_types('analysis_results.txt')\n",
        "\n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á\n",
        "    img = plot_bar_chart(sentiment_counts)\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô base64 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô HTML\n",
        "    img_base64 = base64.b64encode(img.getvalue()).decode('utf-8')\n",
        "\n",
        "    return render_template_string('''\n",
        "        <h1>‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î</h1>\n",
        "        <img src=\"data:image/png;base64,{{img_data}}\" alt=\"Bar Chart\">\n",
        "        <br><br>\n",
        "        <a href=\"/\">‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å</a>\n",
        "    ''', img_data=img_base64)\n",
        "\n",
        "\n",
        "@app.route('/shutdown', methods=['POST'])\n",
        "def shutdown():\n",
        "    shutdown_server()\n",
        "    return 'Server shutting down...'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V2aXWecdbUcn",
        "outputId": "f574bae3-b333-4a70-d839-b7f2c478be91"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.11/dist-packages (5.0.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2024.12.14)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K\n",
            "changed 22 packages in 4s\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0KAuthtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Public URL: NgrokTunnel: \"https://e0ce-34-125-197-63.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://e0ce-34-125-197-63.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:33:35] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:33:36] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:33:39] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:33:40] \"GET / HTTP/1.1\" 200 -\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3592 (\\N{THAI CHARACTER CHO CHAN}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3635 (\\N{THAI CHARACTER SARA AM}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3609 (\\N{THAI CHARACTER NO NU}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3623 (\\N{THAI CHARACTER WO WAEN}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3612 (\\N{THAI CHARACTER PHO PHUNG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3621 (\\N{THAI CHARACTER LO LING}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3585 (\\N{THAI CHARACTER KO KAI}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3634 (\\N{THAI CHARACTER SARA AA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3619 (\\N{THAI CHARACTER RO RUA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3636 (\\N{THAI CHARACTER SARA I}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3648 (\\N{THAI CHARACTER SARA E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3588 (\\N{THAI CHARACTER KHO KHWAI}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3632 (\\N{THAI CHARACTER SARA A}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3627 (\\N{THAI CHARACTER HO HIP}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "<ipython-input-68-2d60dcaf5e91>:126: UserWarning: Glyph 3660 (\\N{THAI CHARACTER THANTHAKHAT}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(img, format='png')\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:33:41] \"GET /result HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2025 04:33:45] \"GET / HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3592 (\\N{THAI CHARACTER CHO CHAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3635 (\\N{THAI CHARACTER SARA AM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3609 (\\N{THAI CHARACTER NO NU}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3623 (\\N{THAI CHARACTER WO WAEN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3612 (\\N{THAI CHARACTER PHO PHUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3621 (\\N{THAI CHARACTER LO LING}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3585 (\\N{THAI CHARACTER KO KAI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3634 (\\N{THAI CHARACTER SARA AA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3619 (\\N{THAI CHARACTER RO RUA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3636 (\\N{THAI CHARACTER SARA I}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3648 (\\N{THAI CHARACTER SARA E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3588 (\\N{THAI CHARACTER KHO KHWAI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3632 (\\N{THAI CHARACTER SARA A}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3627 (\\N{THAI CHARACTER HO HIP}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 3660 (\\N{THAI CHARACTER THANTHAKHAT}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}